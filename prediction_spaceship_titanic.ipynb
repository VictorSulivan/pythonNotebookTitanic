{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prédiction Spaceship Titanic\n",
        "\n",
        "## Contexte du Problème\n",
        "\n",
        "Ce notebook implémente une solution complète pour le challenge Kaggle **Spaceship Titanic**. L'objectif est de prédire si un passager a été transporté vers une autre dimension lors d'une collision spatiale.\n",
        "\n",
        "### Données Disponibles\n",
        "- **train.csv** : 8693 passagers avec la variable cible `Transported`\n",
        "- **test.csv** : Passagers pour lesquels nous devons prédire le transport\n",
        "- **Variables** : 13 features incluant dépenses, planète d'origine, destination, cabine, etc.\n",
        "\n",
        "### Stratégie de Modélisation\n",
        "1. **Prétraitement intelligent** : Gestion des valeurs manquantes et création de features dérivées\n",
        "2. **Feature Engineering** : Extraction d'informations des données structurées\n",
        "3. **Modélisation comparative** : Test de différents algorithmes (Logistic Regression vs Random Forest)\n",
        "4. **Évaluation rigoureuse** : Utilisation de métriques appropriées (Accuracy, ROC-AUC)\n",
        "5. **Prédiction finale** : Entraînement sur tout le dataset et soumission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (8693, 15)\n"
          ]
        }
      ],
      "source": [
        "# Notebook de prédiction Spaceship Titanic (pipeline propre)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "# Charger\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "print('Train:', train_df.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chargement et Exploration des Données\n",
        "\n",
        "### Imports et Configuration\n",
        "Les imports incluent :\n",
        "- **Pandas/Numpy** : Manipulation des données\n",
        "- **Scikit-learn** : Machine Learning (préprocessing, modèles, métriques)\n",
        "- **Modèles testés** : Logistic Regression et Random Forest\n",
        "\n",
        "### Chargement des Données\n",
        "- **Dataset d'entraînement** : 8693 passagers avec leurs informations\n",
        "- **Extraction du GroupId** : Les passagers voyagent en groupes (identifiés par la première partie du PassengerId)\n",
        "- **Taille** : 8693 lignes × 14 colonnes (13 features + target)\n",
        "\n",
        "### Logique Initiale\n",
        "Le `GroupId` est extrait car les passagers voyageant ensemble peuvent avoir des comportements similaires, ce qui sera exploité dans le feature engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (6954, 10) X_val: (1739, 10)\n"
          ]
        }
      ],
      "source": [
        "# Prétraitement + features\n",
        "# Transported -> int 0/1\n",
        "if train_df['Transported'].dtype == 'object':\n",
        "    train_df['Transported'] = train_df['Transported'].map({'True': 1, 'False': 0})\n",
        "train_df['Transported'] = train_df['Transported'].astype(int)\n",
        "\n",
        "# Dépenses -> numériques NaN=0\n",
        "expense_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
        "for c in expense_cols:\n",
        "    train_df[c] = pd.to_numeric(train_df[c], errors='coerce').fillna(0)\n",
        "# Features dépenses\n",
        "train_df['TotalExpenses'] = train_df[expense_cols].sum(axis=1)\n",
        "train_df['HasExpense'] = (train_df['TotalExpenses'] > 0).astype(int)\n",
        "\n",
        "# Catégorielles nettoyées\n",
        "train_df['CryoSleep'] = train_df['CryoSleep'].fillna('Unknown').astype(str)\n",
        "train_df['Destination'] = train_df['Destination'].fillna('Unknown').astype(str)\n",
        "train_df['HomePlanet'] = train_df['HomePlanet'].fillna('Unknown').astype(str)\n",
        "train_df['VIP'] = train_df['VIP'].fillna('Unknown').astype(str)\n",
        "\n",
        "# Groupes\n",
        "train_df['GroupId'] = train_df['PassengerId'].str.split('_').str[0]\n",
        "train_df['GroupSize'] = train_df.groupby('GroupId')['GroupId'].transform('count')\n",
        "\n",
        "# Cabine\n",
        "train_df['Cabin_Deck'] = train_df['Cabin'].str.split('/').str[0]\n",
        "train_df['Cabin_Side'] = train_df['Cabin'].str.split('/').str[2]\n",
        "\n",
        "# Age\n",
        "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
        "\n",
        "feature_cols = ['CryoSleep','HasExpense','TotalExpenses','HomePlanet','Destination',\n",
        "                'GroupSize','Cabin_Deck','Cabin_Side','Age','VIP']\n",
        "X = train_df[feature_cols]\n",
        "y = train_df['Transported']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print('X_train:', X_train.shape, 'X_val:', X_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prétraitement et Feature Engineering\n",
        "\n",
        "### Transformation de la Variable Cible\n",
        "- **Conversion booléenne → numérique** : `True/False` → `1/0` pour la modélisation\n",
        "- **Type casting** : Conversion en entier pour éviter les erreurs\n",
        "\n",
        "### Feature Engineering des Dépenses\n",
        "**Hypothèse** : Les dépenses peuvent être un indicateur de comportement et de statut social.\n",
        "\n",
        "- **Colonnes de dépenses** : RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
        "- **Gestion des NaN** : Remplacement par 0 (logique : pas de dépense = 0)\n",
        "- **Features dérivées** :\n",
        "  - `TotalExpenses` : Somme de toutes les dépenses\n",
        "  - `HasExpense` : Indicateur binaire (1 si dépenses > 0, 0 sinon)\n",
        "\n",
        "### Nettoyage des Variables Catégorielles\n",
        "**Stratégie** : Remplacer les valeurs manquantes par \"Unknown\" plutôt que de les supprimer\n",
        "- **CryoSleep** : État de sommeil cryogénique\n",
        "- **Destination** : Planète de destination\n",
        "- **HomePlanet** : Planète d'origine\n",
        "- **VIP** : Statut VIP\n",
        "\n",
        "### Features de Groupe\n",
        "- **GroupSize** : Nombre de passagers dans le même groupe\n",
        "- **Logique** : Les groupes peuvent avoir des comportements similaires\n",
        "\n",
        "### Parsing de la Cabine\n",
        "- **Cabin_Deck** : Pont de la cabine (A, B, C, etc.)\n",
        "- **Cabin_Side** : Côté du vaisseau (P ou S)\n",
        "- **Logique** : L'emplacement peut influencer la probabilité de transport\n",
        "\n",
        "### Gestion de l'Âge\n",
        "- **Imputation** : Remplacement des NaN par la médiane\n",
        "- **Choix de la médiane** : Plus robuste que la moyenne aux valeurs aberrantes\n",
        "\n",
        "### Sélection des Features Finales\n",
        "10 features retenues pour la modélisation, équilibrant information et simplicité.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== LogReg ===\n",
            "Accuracy: 0.7384 | ROC AUC: 0.7888\n",
            "Matrice de confusion:\n",
            " [[701 162]\n",
            " [293 583]]\n",
            "Rapport de classification:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.705     0.812     0.755       863\n",
            "           1      0.783     0.666     0.719       876\n",
            "\n",
            "    accuracy                          0.738      1739\n",
            "   macro avg      0.744     0.739     0.737      1739\n",
            "weighted avg      0.744     0.738     0.737      1739\n",
            "\n",
            "\n",
            "=== RandomForest ===\n",
            "Accuracy: 0.7188 | ROC AUC: 0.7843\n",
            "Matrice de confusion:\n",
            " [[655 208]\n",
            " [281 595]]\n",
            "Rapport de classification:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.700     0.759     0.728       863\n",
            "           1      0.741     0.679     0.709       876\n",
            "\n",
            "    accuracy                          0.719      1739\n",
            "   macro avg      0.720     0.719     0.718      1739\n",
            "weighted avg      0.721     0.719     0.718      1739\n",
            "\n",
            "\n",
            ">>> Meilleur modèle: LogReg (AUC=0.7888, Acc=0.7384)\n"
          ]
        }
      ],
      "source": [
        "# Pipeline + modèles, évaluation\n",
        "categorical_features = ['CryoSleep','HomePlanet','Destination','Cabin_Deck','Cabin_Side','VIP']\n",
        "numeric_features = ['HasExpense','TotalExpenses','GroupSize','Age']\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', StandardScaler(), numeric_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "log_reg = Pipeline([\n",
        "    ('prep', preprocess),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "rf = Pipeline([\n",
        "    ('prep', preprocess),\n",
        "    ('clf', RandomForestClassifier(n_estimators=400, random_state=42))\n",
        "])\n",
        "\n",
        "models = {'LogReg': log_reg, 'RandomForest': rf}\n",
        "metrics = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_val)\n",
        "    proba = model.predict_proba(X_val)[:,1]\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    auc = roc_auc_score(y_val, proba)\n",
        "    metrics[name] = {'acc': acc, 'auc': auc}\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {round(acc,4)} | ROC AUC: {round(auc,4)}\")\n",
        "    print('Matrice de confusion:\\n', confusion_matrix(y_val, pred))\n",
        "    print('Rapport de classification:\\n', classification_report(y_val, pred, digits=3))\n",
        "\n",
        "best_name = max(metrics, key=lambda k: metrics[k]['auc'])\n",
        "best_model = models[best_name]\n",
        "print(f\"\\n>>> Meilleur modèle: {best_name} (AUC={round(metrics[best_name]['auc'],4)}, Acc={round(metrics[best_name]['acc'],4)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modélisation et Évaluation\n",
        "\n",
        "### Pipeline de Préprocessing\n",
        "**ColumnTransformer** pour gérer différents types de données :\n",
        "- **Variables catégorielles** : OneHotEncoder avec `handle_unknown='ignore'`\n",
        "- **Variables numériques** : StandardScaler pour normalisation\n",
        "- **Avantage** : Pipeline robuste et réutilisable\n",
        "\n",
        "### Modèles Testés\n",
        "\n",
        "#### Logistic Regression\n",
        "- **Avantages** : Rapide, interprétable, bon baseline\n",
        "- **Configuration** : `max_iter=1000` pour convergence\n",
        "- **Résultats** : AUC = 0.7888, Accuracy = 0.7384\n",
        "\n",
        "#### Random Forest\n",
        "- **Avantages** : Capture interactions complexes, robuste au bruit\n",
        "- **Configuration** : 400 estimateurs pour stabilité\n",
        "- **Résultats** : AUC = 0.7843, Accuracy = 0.7188\n",
        "\n",
        "### Stratégie d'Évaluation\n",
        "\n",
        "#### Division Train/Validation\n",
        "- **Split** : 80% train / 20% validation\n",
        "- **Stratification** : Préservation de la distribution des classes\n",
        "- **Random state** : Reproductibilité des résultats\n",
        "\n",
        "#### Métriques Utilisées\n",
        "1. **Accuracy** : Pourcentage de prédictions correctes\n",
        "2. **ROC-AUC** : Capacité discriminatoire du modèle\n",
        "3. **Matrice de confusion** : Détail des erreurs par classe\n",
        "4. **Classification report** : Precision, Recall, F1-score\n",
        "\n",
        "### Sélection du Meilleur Modèle\n",
        "**Critère** : ROC-AUC (plus robuste que l'accuracy pour les problèmes déséquilibrés)\n",
        "- **Gagnant** : Logistic Regression (AUC = 0.7888)\n",
        "- **Performance** : Bon équilibre entre précision et rappel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submission.csv écrit.\n"
          ]
        }
      ],
      "source": [
        "# Refit sur tout le train + prédire test.csv et écrire submission\n",
        "best_model.fit(X, y)\n",
        "Test = pd.read_csv('test.csv')\n",
        "\n",
        "# Recréer features pour Test\n",
        "T = Test.copy()\n",
        "for c in ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']:\n",
        "    T[c] = pd.to_numeric(T[c], errors='coerce').fillna(0)\n",
        "T['TotalExpenses'] = T[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].sum(axis=1)\n",
        "T['HasExpense'] = (T['TotalExpenses'] > 0).astype(int)\n",
        "T['CryoSleep'] = T['CryoSleep'].fillna('Unknown').astype(str)\n",
        "T['Destination'] = T['Destination'].fillna('Unknown').astype(str)\n",
        "T['HomePlanet'] = T['HomePlanet'].fillna('Unknown').astype(str)\n",
        "T['VIP'] = T['VIP'].fillna('Unknown').astype(str)\n",
        "T['GroupId'] = T['PassengerId'].str.split('_').str[0]\n",
        "T['GroupSize'] = T.groupby('GroupId')['GroupId'].transform('count')\n",
        "T['Cabin_Deck'] = T['Cabin'].str.split('/').str[0]\n",
        "T['Cabin_Side'] = T['Cabin'].str.split('/').str[2]\n",
        "T['Age'] = T['Age'].fillna(train_df['Age'].median())\n",
        "\n",
        "X_sub = T[feature_cols]\n",
        "proba = best_model.predict_proba(X_sub)[:,1]\n",
        "pred_bool = proba >= 0.5\n",
        "\n",
        "submission = pd.DataFrame({'PassengerId': T['PassengerId'], 'Transported': pred_bool})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"submission.csv écrit.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prédiction Finale et Soumission\n",
        "\n",
        "### Réentraînement sur le Dataset Complet\n",
        "**Logique** : Une fois le meilleur modèle identifié, on l'entraîne sur toutes les données disponibles pour maximiser les performances.\n",
        "\n",
        "### Traitement du Dataset de Test\n",
        "**Cohérence** : Application exacte du même preprocessing que sur les données d'entraînement :\n",
        "\n",
        "1. **Dépenses** : Conversion numérique + remplacement NaN par 0\n",
        "2. **Features dérivées** : TotalExpenses et HasExpense\n",
        "3. **Variables catégorielles** : Remplissage par \"Unknown\"\n",
        "4. **Groupe** : Calcul du GroupSize\n",
        "5. **Cabine** : Parsing Deck et Side\n",
        "6. **Âge** : Imputation par la médiane du dataset d'entraînement\n",
        "\n",
        "### Stratégie de Prédiction\n",
        "- **Probabilités** : Utilisation de `predict_proba()` pour obtenir les scores de confiance\n",
        "- **Seuil de décision** : 0.5 (peut être optimisé selon les métriques)\n",
        "- **Conversion finale** : Booléen pour le format de soumission\n",
        "\n",
        "### Format de Soumission\n",
        "- **PassengerId** : Identifiants des passagers de test\n",
        "- **Transported** : Prédictions booléennes (True/False)\n",
        "- **Fichier** : `submission.csv` prêt pour Kaggle\n",
        "\n",
        "### Résultat Final\n",
        "Le modèle Logistic Regression, entraîné sur l'ensemble des données avec un preprocessing soigneux, génère des prédictions avec une AUC de 0.7888 sur la validation, prometteuses pour la compétition.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
